{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b85bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d6d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction Functions\n",
    "\n",
    "# 1. Energy and Power\n",
    "def extract_energy(speech):\n",
    "    return librosa.feature.rms(y=speech)[0]  # Root mean square energy\n",
    "\n",
    "# 2. Pitch (Fundamental Frequency) Statistics\n",
    "def extract_pitch(speech, rate):\n",
    "    pitch, _ = librosa.core.piptrack(y=speech, sr=rate)\n",
    "    pitch = pitch[pitch > 0]  # Remove zero values\n",
    "    return pitch\n",
    "\n",
    "# 3. Pitch Statistics\n",
    "def pitch_stats(pitch):\n",
    "    min_pitch = np.min(pitch)\n",
    "    max_pitch = np.max(pitch)\n",
    "    mean_pitch = np.mean(pitch)\n",
    "    pitch_sd = np.std(pitch)\n",
    "    pitch_abs = np.mean(np.abs(pitch))\n",
    "    pitch_quant = np.quantile(pitch, [0.25, 0.5, 0.75])\n",
    "    diff_pitch_max_min = max_pitch - min_pitch\n",
    "    diff_pitch_max_mean = max_pitch - mean_pitch\n",
    "    diff_pitch_max_mode = max_pitch - np.median(pitch)\n",
    "    return min_pitch, max_pitch, mean_pitch, pitch_sd, pitch_abs, pitch_quant, diff_pitch_max_min, diff_pitch_max_mean, diff_pitch_max_mode\n",
    "\n",
    "# 4. Intensity (RMS)\n",
    "def intensity_features(speech):\n",
    "    intensity = librosa.feature.rms(y=speech)[0]\n",
    "    intensity_min = np.min(intensity)\n",
    "    intensity_max = np.max(intensity)\n",
    "    intensity_mean = np.mean(intensity)\n",
    "    intensity_sd = np.std(intensity)\n",
    "    intensity_quant = np.quantile(intensity, [0.25, 0.5, 0.75])\n",
    "    diff_int_max_min = intensity_max - intensity_min\n",
    "    diff_int_max_mean = intensity_max - intensity_mean\n",
    "    diff_int_max_mode = intensity_max - np.median(intensity)\n",
    "    return intensity_min, intensity_max, intensity_mean, intensity_sd, intensity_quant, diff_int_max_min, diff_int_max_mean, diff_int_max_mode\n",
    "\n",
    "# 5. Jitter and Shimmer\n",
    "def jitter_shimmer(speech, rate):\n",
    "    # Jitter: Measure of pitch variation\n",
    "    pitch, voiced_flag = librosa.core.piptrack(y=speech, sr=rate)\n",
    "    jitter = np.std(pitch[pitch > 0])\n",
    "    \n",
    "    # Shimmer: Measure of amplitude variation (calculated based on RMS)\n",
    "    intensity = librosa.feature.rms(y=speech)[0]\n",
    "    shimmer = np.std(intensity)\n",
    "    \n",
    "    return jitter, shimmer\n",
    "\n",
    "# 6. Speech Rate and Pauses\n",
    "def speech_rate(speech, rate):\n",
    "    onset_env = librosa.onset.onset_strength(y=speech, sr=rate)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=rate)\n",
    "    speak_rate = len(onset_frames) / (len(speech) / rate)  # Onsets per second\n",
    "    return speak_rate\n",
    "\n",
    "def pause_features(speech, rate):\n",
    "    onset_env = librosa.onset.onset_strength(y=speech, sr=rate)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=rate)\n",
    "    intervals = librosa.frames_to_time(onset_frames, sr=rate)  # Time intervals between onsets\n",
    "    pauses = np.diff(intervals)  # Calculate pause durations\n",
    "    max_pause = np.max(pauses) if len(pauses) > 0 else 0\n",
    "    avg_pause = np.mean(pauses) if len(pauses) > 0 else 0\n",
    "    total_pause_duration = np.sum(pauses)\n",
    "    return max_pause, avg_pause, total_pause_duration\n",
    "\n",
    "# 7. Rising and Falling Edges (Pitch changes)\n",
    "def rising_falling_edges(pitch):\n",
    "    rising = np.sum(np.diff(pitch) > 0)\n",
    "    falling = np.sum(np.diff(pitch) < 0)\n",
    "    max_rising = np.max(np.diff(pitch)[np.diff(pitch) > 0]) if len(np.diff(pitch)) > 0 else 0\n",
    "    max_falling = np.min(np.diff(pitch)[np.diff(pitch) < 0]) if len(np.diff(pitch)) > 0 else 0\n",
    "    avg_rise = np.mean(np.diff(pitch)[np.diff(pitch) > 0]) if len(np.diff(pitch)) > 0 else 0\n",
    "    avg_fall = np.mean(np.diff(pitch)[np.diff(pitch) < 0]) if len(np.diff(pitch)) > 0 else 0\n",
    "    return rising, falling, max_rising, max_falling, avg_rise, avg_fall\n",
    "\n",
    "# 8. Loudness (RMS energy)\n",
    "def loudness(speech):\n",
    "    return librosa.feature.rms(y=speech)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bb0ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPassOrFail(df, person_id, column_name):\n",
    "    \"\"\"\n",
    "    Calculate the average score for a given person and column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the data.\n",
    "        person_id (str): The participant ID (e.g., \"p1\").\n",
    "        column_name (str): The name of the column to average (e.g., \"Overall\").\n",
    "\n",
    "    Returns:\n",
    "        float: The average score for the specified column and person.\n",
    "    \"\"\"\n",
    "    person_data = df[df[\"Participant\"] == person_id]\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in dataframe.\")\n",
    "    if person_data.empty:\n",
    "        raise ValueError(f\"No data found for participant '{person_id}'.\")\n",
    "    \n",
    "    averageScore = person_data[column_name].astype(float).mean()\n",
    "\n",
    "    if averageScore >= 5:\n",
    "        return 1 # Pass\n",
    "    else:\n",
    "        return 0 # Fail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e04cb964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 1\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n",
      "passOrFail: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store the features \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Create a DataFrame to store the features\n",
    "\n",
    "# I want this dataframe to have the following columns:\n",
    "# 'Energy', 'Pitch Min', 'Pitch Max', 'Pitch Mean', 'Pitch Std Dev', 'Intensity Min', 'Intensity Max', 'Intensity Mean', 'Jitter', 'Shimmer', 'Speech Rate', 'Max Pause', 'Avg Pause', 'Total Pause Duration'\n",
    "\n",
    "# The first column should be the filename of the audio file\n",
    "# The last column should be whether they passed or failed the interview, for now just set it to 'pass'\n",
    "\n",
    "\n",
    "# Step 1: Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=['Filename', 'Energy', 'Pitch Min', 'Pitch Max', 'Pitch Mean', 'Pitch Std Dev', 'Intensity Min', 'Intensity Max', 'Intensity Mean', 'Jitter', 'Shimmer', 'Speech Rate', 'Max Pause', 'Avg Pause', 'Total Pause Duration', 'Result'])\n",
    "\n",
    "\n",
    "df_prosodic_features = pd.read_csv('../MIT_INTERVIEW_DATASET/Prosody/prosodic_features.csv')\n",
    "\n",
    "\n",
    "df_labels_from_turkers = pd.read_csv('../MIT_INTERVIEW_DATASET/Labels/turker_scores_full_interview.csv')\n",
    "\n",
    "# Step 2: Loop through the audio files and extract features\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i in range(90):\n",
    "    AUDIO_FILE = f'../MIT_INTERVIEW_DATASET/Audio/P{i}.wav'\n",
    "    if os.path.exists(AUDIO_FILE):\n",
    "        speech, rate = librosa.load(AUDIO_FILE, sr=16000)\n",
    "        energy = extract_energy(speech)\n",
    "        pitch = extract_pitch(speech, rate)\n",
    "        min_pitch, max_pitch, mean_pitch, pitch_sd, *_ = pitch_stats(pitch)\n",
    "        intensity_min, intensity_max, intensity_mean, *_ = intensity_features(speech)\n",
    "        jitter, shimmer = jitter_shimmer(speech, rate)\n",
    "        speak_rate = speech_rate(speech, rate)\n",
    "        max_pause, avg_pause, total_pause_duration = pause_features(speech, rate)\n",
    "        \n",
    "        rowNameFromTurkers = f\"p{i}\"\n",
    "        columnNameFromTurkers = \"Overall\"\n",
    "        passOrFail = getPassOrFail(df_labels_from_turkers, rowNameFromTurkers, columnNameFromTurkers)\n",
    "\n",
    "        print(f\"passOrFail: {passOrFail}\")\n",
    "\n",
    "\n",
    "        rows.append({\n",
    "            'Filename': AUDIO_FILE,\n",
    "            'Energy': np.mean(energy),\n",
    "            'Pitch Min': min_pitch,\n",
    "            'Pitch Max': max_pitch,\n",
    "            'Pitch Mean': mean_pitch,\n",
    "            'Pitch Std Dev': pitch_sd,\n",
    "            'Intensity Min': intensity_min,\n",
    "            'Intensity Max': intensity_max,\n",
    "            'Intensity Mean': intensity_mean,\n",
    "            'Jitter': jitter,\n",
    "            'Shimmer': shimmer,\n",
    "            'Speech Rate': speak_rate,\n",
    "            'Max Pause': max_pause,\n",
    "            'Avg Pause': avg_pause,\n",
    "            'Total Pause Duration': total_pause_duration,\n",
    "            'Result': passOrFail\n",
    "        })\n",
    "    \n",
    "\n",
    "    AUDIO_FILE = f'../MIT_INTERVIEW_DATASET/Audio/PP{i}.wav'\n",
    "    if os.path.exists(AUDIO_FILE):\n",
    "        speech, rate = librosa.load(AUDIO_FILE, sr=16000)\n",
    "        energy = extract_energy(speech)\n",
    "        pitch = extract_pitch(speech, rate)\n",
    "        min_pitch, max_pitch, mean_pitch, pitch_sd, *_ = pitch_stats(pitch)\n",
    "        intensity_min, intensity_max, intensity_mean, *_ = intensity_features(speech)\n",
    "        jitter, shimmer = jitter_shimmer(speech, rate)\n",
    "        speak_rate = speech_rate(speech, rate)\n",
    "        max_pause, avg_pause, total_pause_duration = pause_features(speech, rate)\n",
    "        \n",
    "        rowNameFromTurkers = f\"p{i}\"\n",
    "        columnNameFromTurkers = \"Overall\"\n",
    "        passOrFail = getPassOrFail(df_labels_from_turkers, rowNameFromTurkers, columnNameFromTurkers)\n",
    "\n",
    "        print(f\"passOrFail: {passOrFail}\")\n",
    "\n",
    "\n",
    "        rows.append({\n",
    "            'Filename': AUDIO_FILE,\n",
    "            'Energy': np.mean(energy),\n",
    "            'Pitch Min': min_pitch,\n",
    "            'Pitch Max': max_pitch,\n",
    "            'Pitch Mean': mean_pitch,\n",
    "            'Pitch Std Dev': pitch_sd,\n",
    "            'Intensity Min': intensity_min,\n",
    "            'Intensity Max': intensity_max,\n",
    "            'Intensity Mean': intensity_mean,\n",
    "            'Jitter': jitter,\n",
    "            'Shimmer': shimmer,\n",
    "            'Speech Rate': speak_rate,\n",
    "            'Max Pause': max_pause,\n",
    "            'Avg Pause': avg_pause,\n",
    "            'Total Pause Duration': total_pause_duration,\n",
    "            'Result': passOrFail\n",
    "        })\n",
    "    \n",
    "\n",
    "# Now create DataFrame\n",
    "df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0211cdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 7  9]\n",
      " [ 0 12]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61        16\n",
      "           1       0.57      1.00      0.73        12\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.79      0.72      0.67        28\n",
      "weighted avg       0.82      0.68      0.66        28\n",
      "\n",
      "\n",
      "Accuracy Score: 0.6785714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Step 1: Prepare features and labels\n",
    "X = df.drop(columns=['Filename', 'Result'])  # Features\n",
    "y = df['Result']  # Labels (0 = Fail, 1 = Pass)\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Train the model (Random Forest in this case)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b716314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'interview_pass_fail_model-try1-67Percent.pkl')\n",
    "\n",
    "# Save the scaler as well\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c962bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model back \n",
    "\n",
    "loaded_model = joblib.load('interview_pass_fail_model-try1-67Percent.pkl')\n",
    "loaded_scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "\n",
    "# new_data = None\n",
    "# new_data_Scaled = loaded_scaler.transform(new_data)\n",
    "\n",
    "# prediction = loaded_model.predict(new_data_Scaled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confident-ai-project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
